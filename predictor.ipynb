{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging improved.\n"
     ]
    }
   ],
   "source": [
    "from share import *\n",
    "import config\n",
    "\n",
    "import cv2\n",
    "import einops\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "from annotator.util import resize_image, HWC3\n",
    "from annotator.canny import CannyDetector\n",
    "from cldm.model import create_model, load_state_dict\n",
    "from cldm.ddim_hacked import DDIMSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75038943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from .predictor import Predictor\n",
    "\n",
    "predictor = Predictor(config_path, weight_path) #config path is the yaml file\n",
    "out_gen = predictor.gen(input_image, prompts) # input_image:np.ndarray and prompts a list of str\n",
    "\n",
    "# and then to get each result\n",
    "for res in out_gen:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c1f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, config_path, weight_path):\n",
    "        self.apply_canny = CannyDetector()\n",
    "        self.model = create_model(str(config_path)).cpu()\n",
    "        self.model.load_state_dict(load_state_dict(str(weight_path), location='cuda')).cuda()\n",
    "        self.ddim_sampler = DDIMSampler(model)\n",
    "\n",
    "    def gen(input_image, prompts, **kwargs):\n",
    "        for prompt in prompts:\n",
    "            yield self.process(input_image, prompt, **kwargs)\n",
    "                \n",
    "    def process(input_image,\n",
    "                prompt,\n",
    "                a_prompt='',\n",
    "                n_prompt='',\n",
    "                num_samples=2,\n",
    "                image_resolution=512,\n",
    "                ddim_steps=20,\n",
    "                guess_mode=False,\n",
    "                strength=1.0,\n",
    "                low_threshold=100,\n",
    "                high_threshold=200,\n",
    "                scale=9.0,\n",
    "                seed=42,\n",
    "                eta=0.0):\n",
    "        with torch.no_grad():\n",
    "            img = resize_image(HWC3(input_image), image_resolution)\n",
    "            H, W, C = img.shape\n",
    "\n",
    "            detected_map = apply_canny(img, low_threshold, high_threshold)\n",
    "            detected_map = HWC3(detected_map)\n",
    "\n",
    "            control = torch.from_numpy(detected_map.copy()).float().cuda() / 255.0\n",
    "            control = torch.stack([control for _ in range(num_samples)], dim=0)\n",
    "            control = einops.rearrange(control, 'b h w c -> b c h w').clone()\n",
    "\n",
    "            if seed == -1:\n",
    "                seed = random.randint(0, 65535)\n",
    "            seed_everything(seed)\n",
    "\n",
    "            if config.save_memory:\n",
    "                self.model.low_vram_shift(is_diffusing=False)\n",
    "\n",
    "            cond = {\"c_concat\": [control], \"c_crossattn\": [self.model.get_learned_conditioning([prompt + ', ' + a_prompt] * num_samples)]}\n",
    "            un_cond = {\"c_concat\": None if guess_mode else [control], \"c_crossattn\": [self.model.get_learned_conditioning([n_prompt] * num_samples)]}\n",
    "            shape = (4, H // 8, W // 8)\n",
    "\n",
    "            if config.save_memory:\n",
    "                self.model.low_vram_shift(is_diffusing=True)\n",
    "\n",
    "            self.model.control_scales = [strength * (0.825 ** float(12 - i)) for i in range(13)] if guess_mode else ([strength] * 13)  # Magic number. IDK why. Perhaps because 0.825**12<0.01 but 0.826**12>0.01\n",
    "            samples, intermediates = self.ddim_sampler.sample(ddim_steps, num_samples,\n",
    "                                                         shape, cond, verbose=False, eta=eta,\n",
    "                                                         unconditional_guidance_scale=scale,\n",
    "                                                         unconditional_conditioning=un_cond)\n",
    "\n",
    "            if config.save_memory:\n",
    "                self.model.low_vram_shift(is_diffusing=False)\n",
    "\n",
    "            x_samples = self.model.decode_first_stage(samples)\n",
    "            x_samples = (einops.rearrange(x_samples, 'b c h w -> b h w c') * 127.5 + 127.5).cpu().numpy().clip(0, 255).astype(np.uint8)\n",
    "\n",
    "            results = [x_samples[i] for i in range(num_samples)]\n",
    "        return [255 - detected_map] + results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790aac72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:allpolvo]",
   "language": "python",
   "name": "conda-env-allpolvo-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
